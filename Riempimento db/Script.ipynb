{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-21T18:00:27.020213Z",
     "start_time": "2025-01-21T18:00:26.968704Z"
    }
   },
   "source": [
    "import psycopg2\n",
    "from psycopg2 import OperationalError\n",
    "\n",
    "# Configurazione del database\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"Movies_DB\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Cetriolo20!\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "}\n",
    "\n",
    "def create_connection():\n",
    "    \"\"\"Crea una connessione al database PostgreSQL.\"\"\"\n",
    "    try:\n",
    "        print(\"Tentativo di connessione al database...\")\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        print(\"Connessione al database avvenuta con successo!\")\n",
    "        return conn\n",
    "    except OperationalError as e:\n",
    "        print(f\"Errore durante la connessione al database: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test della connessione\n",
    "if __name__ == \"__main__\":\n",
    "    connection = create_connection()\n",
    "    if connection:\n",
    "        connection.close()\n",
    "        print(\"Connessione chiusa correttamente.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentativo di connessione al database...\n",
      "Connessione al database avvenuta con successo!\n",
      "Connessione chiusa correttamente.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T19:45:11.607048Z",
     "start_time": "2025-01-21T19:45:11.505465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "\n",
    "# Configurazione del database\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"Movies_DB\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Cetriolo20!\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "}\n",
    "\n",
    "# Elenco delle tabelle da svuotare (in ordine per evitare errori di FK)\n",
    "TABLES = [\n",
    "    \"actors\",\n",
    "    \"countries\",\n",
    "    \"crew\",\n",
    "    \"genres\",\n",
    "    \"languages\",\n",
    "    \"movies\",\n",
    "    \"posters\",\n",
    "    \"releases\",\n",
    "    \"studios\",\n",
    "    \"themes\",\n",
    "    \"rotten_tomatoes_reviews\",\n",
    "    \"oscar_awards\",\n",
    "]\n",
    "\n",
    "def clear_tables():\n",
    "    \"\"\"Cancella tutte le entry dalle tabelle del database.\"\"\"\n",
    "    try:\n",
    "        # Connessione al database\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        conn.autocommit = True  # Attiva la modalità autocommit\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        print(\"Inizio cancellazione dei dati...\")\n",
    "\n",
    "        for table in TABLES:\n",
    "            query = sql.SQL(\"TRUNCATE TABLE {} CASCADE\").format(sql.Identifier(table))\n",
    "            cursor.execute(query)\n",
    "            print(f\"Tabella '{table}' svuotata con successo.\")\n",
    "\n",
    "        print(\"Tutte le tabelle sono state svuotate correttamente.\")\n",
    "\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante la cancellazione delle tabelle: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    clear_tables()\n"
   ],
   "id": "577acb03edf61ed6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inizio cancellazione dei dati...\n",
      "Tabella 'actors' svuotata con successo.\n",
      "Tabella 'countries' svuotata con successo.\n",
      "Tabella 'crew' svuotata con successo.\n",
      "Tabella 'genres' svuotata con successo.\n",
      "Tabella 'languages' svuotata con successo.\n",
      "Tabella 'movies' svuotata con successo.\n",
      "Tabella 'posters' svuotata con successo.\n",
      "Tabella 'releases' svuotata con successo.\n",
      "Tabella 'studios' svuotata con successo.\n",
      "Tabella 'themes' svuotata con successo.\n",
      "Tabella 'rotten_tomatoes_reviews' svuotata con successo.\n",
      "Tabella 'oscar_awards' svuotata con successo.\n",
      "Tutte le tabelle sono state svuotate correttamente.\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T10:16:41.796343Z",
     "start_time": "2025-01-22T10:15:27.479075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import csv\n",
    "import io\n",
    "\n",
    "# Configurazione della connessione al database\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"Movies_DB\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"Cetriolo20!\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "}\n",
    "\n",
    "# Configurazione delle tabelle e relativi file CSV\n",
    "CSV_FILES = [\n",
    "    {\"table\": \"actors\", \"file\": \"C:/Users/franc/PycharmProjects/Assignment 2024-2025/pythonProject/Data/actors.csv\", \"columns\": [\"id\", \"name\", \"role\"]},\n",
    "    {\"table\": \"countries\", \"file\": \"C:/Users/franc/PycharmProjects/Assignment 2024-2025/pythonProject/Data/countries.csv\", \"columns\": [\"id\", \"country\"]},\n",
    "    {\"table\": \"crew\", \"file\": \"C:/Users/franc/PycharmProjects/Assignment 2024-2025/pythonProject/Data/crew.csv\", \"columns\": [\"id\", \"role\", \"name\"]},\n",
    "    {\"table\": \"genres\", \"file\": \"C:/Users/franc/PycharmProjects/Assignment 2024-2025/pythonProject/Data/genres.csv\", \"columns\": [\"id\", \"genre\"]},\n",
    "    {\"table\": \"languages\", \"file\": \"C:/Users/franc/PycharmProjects/Assignment 2024-2025/pythonProject/Data/languages.csv\", \"columns\": [\"id\", \"type\", \"language\"]},\n",
    "    {\"table\": \"movies\", \"file\": \"C:/Users/franc/PycharmProjects/Assignment 2024-2025/pythonProject/Data/movies.csv\", \"columns\": [\"id\", \"name\", \"date\", \"tagline\", \"description\", \"minute\", \"rating\"]},\n",
    "    {\"table\": \"posters\", \"file\": \"C:/Users/franc/PycharmProjects/Assignment 2024-2025/pythonProject/Data/posters.csv\", \"columns\": [\"id\", \"link\"]},\n",
    "    {\"table\": \"releases\", \"file\": \"C:/Users/franc/PycharmProjects/Assignment 2024-2025/pythonProject/Data/releases.csv\", \"columns\": [\"id\", \"country\", \"date\", \"type\", \"rating\"]},\n",
    "    {\"table\": \"studios\", \"file\": \"C:/Users/franc/PycharmProjects/Assignment 2024-2025/pythonProject/Data/studios.csv\", \"columns\": [\"id\", \"studio\"]},\n",
    "    {\"table\": \"themes\", \"file\": \"C:/Users/franc/PycharmProjects/Assignment 2024-2025/pythonProject/Data/themes.csv\", \"columns\": [\"id\", \"theme\"]},\n",
    "    {\"table\": \"oscar_awards\", \"file\": \"C:/Users/franc/PycharmProjects/Assignment 2024-2025/pythonProject/Data/the_oscar_awards.csv\", \"columns\": [\"year_film\", \"year_ceremony\", \"ceremony\", \"category\", \"name\", \"film\", \"winner\"]},\n",
    "    {\"table\": \"rotten_tomatoes_reviews\", \"file\": \"C:/Users/franc/PycharmProjects/Assignment 2024-2025/pythonProject/Data/rotten_tomatoes_reviews.csv\", \"columns\": [\"rotten_tomatoes_link\", \"movie_title\", \"critic_name\", \"top_critic\", \"publisher_name\", \"review_type\", \"review_score\", \"review_date\", \"review_content\"]},\n",
    "]\n",
    "\n",
    "# Funzione per rimuovere i vincoli di unicità\n",
    "def remove_constraints(cursor):\n",
    "    tables_to_update = [\"actors\", \"countries\", \"crew\", \"genres\", \"languages\", \"posters\", \"releases\", \"studios\", \"themes\"]\n",
    "    for table in tables_to_update:\n",
    "        constraint_name = f\"{table}_pkey\"\n",
    "        try:\n",
    "            cursor.execute(\n",
    "                sql.SQL(\"ALTER TABLE {} DROP CONSTRAINT IF EXISTS {};\")\n",
    "                .format(sql.Identifier(table), sql.Identifier(constraint_name))\n",
    "            )\n",
    "            print(f\"Vincolo di unicità rimosso da '{table}'.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Errore durante la rimozione del vincolo di unicità per '{table}': {e}\")\n",
    "\n",
    "def filter_and_import_csv(cursor, table_name, file_path, columns):\n",
    "    try:\n",
    "        if table_name == \"rotten_tomatoes_reviews\":\n",
    "            normalized_data = io.StringIO()\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                reader = csv.DictReader(file)\n",
    "                writer = csv.DictWriter(normalized_data, fieldnames=columns)\n",
    "                writer.writeheader()\n",
    "\n",
    "                for row in reader:\n",
    "                    score = row[\"review_score\"]\n",
    "                    try:\n",
    "                        # Convertire '3.5/5' in un valore numerico\n",
    "                        if \"/\" in score:\n",
    "                            numerator, denominator = map(float, score.split(\"/\"))\n",
    "                            if denominator == 0:  # Evitare divisioni per zero\n",
    "                                row[\"review_score\"] = None\n",
    "                            else:\n",
    "                                row[\"review_score\"] = numerator / denominator\n",
    "                        else:\n",
    "                            row[\"review_score\"] = float(score)\n",
    "                    except (ValueError, TypeError):\n",
    "                        row[\"review_score\"] = None\n",
    "                    writer.writerow(row)\n",
    "\n",
    "            normalized_data.seek(0)\n",
    "            file_to_import = normalized_data\n",
    "        elif table_name == \"posters\":\n",
    "            filtered_data = io.StringIO()\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                reader = csv.DictReader(file)\n",
    "                writer = csv.DictWriter(filtered_data, fieldnames=columns)\n",
    "                writer.writeheader()\n",
    "                for row in reader:\n",
    "                    if row[\"link\"] and row[\"link\"].strip().lower() != \"null\":\n",
    "                        writer.writerow(row)\n",
    "            filtered_data.seek(0)\n",
    "            file_to_import = filtered_data\n",
    "        else:\n",
    "            file_to_import = open(file_path, \"r\", encoding=\"utf-8\")\n",
    "\n",
    "        # Importazione dei dati\n",
    "        cursor.copy_expert(\n",
    "            sql.SQL(\"\"\"\n",
    "                COPY {} ({}) FROM STDIN WITH (FORMAT CSV, HEADER TRUE, QUOTE '\"', NULL '')\n",
    "            \"\"\").format(\n",
    "                sql.Identifier(table_name),\n",
    "                sql.SQL(\", \").join(map(sql.Identifier, columns))\n",
    "            ),\n",
    "            file_to_import\n",
    "        )\n",
    "        print(f\"Dati importati con successo nella tabella '{table_name}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante l'importazione nella tabella '{table_name}': {e}\")\n",
    "    finally:\n",
    "        if table_name in [\"rotten_tomatoes_reviews\", \"posters\"]:\n",
    "            file_to_import.close()\n",
    "        else:\n",
    "            file_to_import.close()\n",
    "\n",
    "# Funzione principale\n",
    "def main():\n",
    "    try:\n",
    "        # Connessione al database\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Rimuove vincoli di unicità per le tabelle escluse\n",
    "        remove_constraints(cursor)\n",
    "\n",
    "        for csv_file in CSV_FILES:\n",
    "            table_name = csv_file[\"table\"]\n",
    "            file_path = csv_file[\"file\"]\n",
    "            columns = csv_file[\"columns\"]\n",
    "            filter_and_import_csv(cursor, table_name, file_path, columns)\n",
    "\n",
    "        conn.commit()\n",
    "        print(\"Tutti i dati sono stati importati con successo.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante il processo di importazione: {e}\")\n",
    "    finally:\n",
    "        if 'cursor' in locals():\n",
    "            cursor.close()\n",
    "        if 'conn' in locals():\n",
    "            conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "a90e41e93fbe0ef1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vincolo di unicità rimosso da 'actors'.\n",
      "Vincolo di unicità rimosso da 'countries'.\n",
      "Vincolo di unicità rimosso da 'crew'.\n",
      "Vincolo di unicità rimosso da 'genres'.\n",
      "Vincolo di unicità rimosso da 'languages'.\n",
      "Vincolo di unicità rimosso da 'posters'.\n",
      "Vincolo di unicità rimosso da 'releases'.\n",
      "Vincolo di unicità rimosso da 'studios'.\n",
      "Vincolo di unicità rimosso da 'themes'.\n",
      "Dati importati con successo nella tabella 'actors'.\n",
      "Dati importati con successo nella tabella 'countries'.\n",
      "Dati importati con successo nella tabella 'crew'.\n",
      "Dati importati con successo nella tabella 'genres'.\n",
      "Dati importati con successo nella tabella 'languages'.\n",
      "Dati importati con successo nella tabella 'movies'.\n",
      "Dati importati con successo nella tabella 'posters'.\n",
      "Dati importati con successo nella tabella 'releases'.\n",
      "Dati importati con successo nella tabella 'studios'.\n",
      "Dati importati con successo nella tabella 'themes'.\n",
      "Dati importati con successo nella tabella 'oscar_awards'.\n",
      "Dati importati con successo nella tabella 'rotten_tomatoes_reviews'.\n",
      "Tutti i dati sono stati importati con successo.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T10:35:59.311618Z",
     "start_time": "2025-01-22T10:35:56.582189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import psycopg2\n",
    "\n",
    "# Dettagli di connessione al db\n",
    "host = 'localhost' \n",
    "dbname = 'Movies_DB'\n",
    "user = 'postgres'\n",
    "password = 'Cetriolo20!'\n",
    "\n",
    "# Connessione al database\n",
    "conn = psycopg2.connect(host=host, dbname=dbname, user=user, password=password)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Query per ottenere il nome di tutte le tabelle nel database\n",
    "cur.execute(\"\"\"\n",
    "    SELECT table_name\n",
    "    FROM information_schema.tables\n",
    "    WHERE table_schema = 'public'\n",
    "\"\"\")\n",
    "\n",
    "tables = cur.fetchall()\n",
    "\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    cur.execute(f\"SELECT COUNT(*) FROM {table_name}\")\n",
    "    row_count = cur.fetchone()[0]\n",
    "    print(f\"Tabella {table_name} contiene {row_count} righe.\")\n",
    "\n",
    "# Chiude connessione\n",
    "cur.close()\n",
    "conn.close()\n"
   ],
   "id": "81509e8773fd1500",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabella countries contiene 693476 righe.\n",
      "Tabella actors contiene 5798450 righe.\n",
      "Tabella crew contiene 4720183 righe.\n",
      "Tabella genres contiene 1046849 righe.\n",
      "Tabella languages contiene 1038762 righe.\n",
      "Tabella movies contiene 941597 righe.\n",
      "Tabella posters contiene 760885 righe.\n",
      "Tabella releases contiene 1332782 righe.\n",
      "Tabella studios contiene 679283 righe.\n",
      "Tabella themes contiene 125641 righe.\n",
      "Tabella rotten_tomatoes_reviews contiene 1129887 righe.\n",
      "Tabella oscar_awards contiene 10889 righe.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T10:36:10.050976Z",
     "start_time": "2025-01-22T10:36:05.960512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "\n",
    "def count_rows_in_csv(file_path):\n",
    "    try:\n",
    "        with open(file_path, newline='', encoding='utf-8') as csvfile:\n",
    "            csvreader = csv.reader(csvfile)\n",
    "            row_count = sum(1 for row in csvreader)  # Conta tutte le righe\n",
    "        return row_count\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not trovato: {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Errore: {e}\")\n",
    "        return None\n",
    "\n",
    "file_path = 'C:/Users/franc/PycharmProjects/Assignment 2024-2025/pythonProject/Data/actors.csv'\n",
    "num_rows = count_rows_in_csv(file_path)\n",
    "\n",
    "if num_rows is not None:\n",
    "    print(f\"Il file CSV contiene {num_rows} righe.\")\n"
   ],
   "id": "826212662a6f93d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il file CSV contiene 5798451 righe.\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
